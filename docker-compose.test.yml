version: '3.2'
volumes:
  bundle_cache: {}
  scrapy_shared:
  db_data:
  db_backup:
  api_data:
  # bot_data:
  search_data:
  scrapydo_data:
  splash_data:
  # mongo_data:
services:
  app:
    build:
      context: ./web
      dockerfile: ./Dockerfile
    depends_on:
      - db
      - api
      # - search
      # - bot
      - scrapy
    volumes:
      - scrapy_shared:/var/www/scrapy/data
      - bundle_cache:/bundle
      - ./web/app:/var/www/alegreme/app
      - ./web/config:/var/www/alegreme/config
      - ./web/db/backups:/var/www/alegreme/db/backups
      - ./web/test:/var/www/alegreme/test
      - ./storage:/var/www/alegreme/storage
    environment:
      RAILS_ENV: test
      RACK_ENV: test
      RAILS_SERVE_STATIC_FILES: 'false'
      PGHOST: db
      PGUSER: postgres
      # AWS_ACCESS_KEY_ID: REMOVED
      # AWS_SECRET_ACCESS_KEY: REMOVED
      # AWS_BUCKET: alegreme-event-cover
      API_URL: http://api
      ELASTICSEARCH_URL: http://search:9200
      IS_DOCKER: 'true'
      HTTP_HOST: 'alegreme.com'
      NODE_ENV: test
    links:
      # - api
      - db
      # - search
    restart: always
    ports:
      - 3000:3000
  db:
    image: postgres
    volumes:
      - db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: docker
      POSTGRES_DB: db
      TZ: 'America/Sao_Paulo'
      PGTZ: 'America/Sao_Paulo'
    ports:
      - 5432:5432
    restart: always
  # web:
  #   build:
  #     context: ./web
  #     dockerfile: ./docker/web/Dockerfile
  #   depends_on:
  #     - app
  #   ports:
  #     - 80:80
  #     - 443:443
  #   volumes:
  #     - ./data/certbot/conf:/etc/letsencrypt
  #     - ./data/certbot/www:/var/www/certbot
  #   restart: always
  # certbot:
  #   image: certbot/certbot
  #   volumes:
  #     - ./data/certbot/conf:/etc/letsencrypt
  #     - ./data/certbot/www:/var/www/certbot
  api:
    build:
      context: ./ml
      dockerfile: ./Dockerfile
    ports:
      - "5000:5000"
    volumes:
      - api_data:/var/www/api/data
      - scrapy_shared:/var/www/scrapy/data
    environment:
      IS_DOCKER: 'true'
  # bot:
  #   build:
  #     context: ./bot
  #     dockerfile: ./Dockerfile
  #   ports:
  #     - "3030:3030"
  #   volumes:
  #     - bot_data:/var/www/bot/data
  #   environment:
  #     MONGO_URI: mongodb://jon:password@mongo:27017
  #     PRIVATE_IP: '172.26.14.59'
  #     PUBLIC_IP: '3.209.95.87'
  #     WEB_DOMAIN: 'https://www.alegreme.com'
  #   restart: always
  #   depends_on:
  #     - mongo
  # search:
  #   build:
  #     context: ./search
  #     dockerfile: ./Dockerfile
  #   environment:
  #     discovery.type: single-node
  #   ports:
  #     - "9200:9200"
  #   volumes:
  #     - search_data:/var/www/search/data
  #   restart: always
  scrapy:
    build:
      context: ./scrapy
      dockerfile: ./Dockerfile
    environment:
        SPLASH_URL: http://splash:8050
        IS_DOCKER: 'true'
        # PRIVATE_IP: '172.26.14.59'
        # PUBLIC_IP: '3.209.95.87'
    depends_on:
      - splash
    volumes:
      - scrapy_shared:/var/www/scrapy/data
      - scrapydo_data:/var/www/scrapy/projects
    ports:
      - "7654:7654"
    restart: always
  splash:
    image: scrapinghub/splash
    ports:
      - "8050:8050"
      - "5023:5023"
    restart: always
    volumes:
      - splash_data:/var/www/splash/data
  # mongo:
  #   image: mongo:4.1
  #   restart: always
  #   environment:
  #     MONGO_INITDB_ROOT_USERNAME: jon
  #     MONGO_INITDB_ROOT_PASSWORD: password
  #   volumes:
  #     - mongo_data:/data/db
